[
  {
    "id": 1000,
    "date": "2020/10/20",
    "title": "Mulesoft",
    "itemList": [
      {
        "text": "<p>A Mule event contains the core information processed by the runtime. It travels through components inside your Mule app following the configured application logic.</p><p>Note that the Mule event is immutable, so every change to an instance of a Mule event results in the creation of a new instance.</p><p>A Mule event is generated when a trigger (such as an HTTP request or a change to a database or file) reaches the Event source of a flow. This trigger could be an external event triggered by a resource that might be external to the Mule app.</p>",
        "image": "../assets/image/server/otherProduct/mulesoftEvent.PNG",
        "imageClass": "mx-auto d-block"
      }
    ]
  },
  {
    "id": 1200,
    "date": "2020/10/20",
    "title": "Anypoint Platform CLI",
    "itemList": [
      {
        "text": "<p>Prerequisites:<ul><li>NodeJS and npm</li><li>Git</li><ul></p>",
        "image": ""
      },
      {
        "text": "<p>Installation: <code>npm install -g anypoint-cli@latest</code></p>",
        "image": ""
      },
      {
        "text": "<p>Usage: <code>anypoint-cli --username yupinggaogmail</code></p>",
        "image": ""
      }
    ]
  },
  {
    "id": 1300,
    "date": "2020/10/30",
    "title": "Salesforce",
    "itemList": [
      {
        "text": "<p><b>Salesforce Architecture</b><br>When you think about the Salesforce architecture, imagine a series of layers that sit on top of each other. Sometimes it helps to think of it as a cake because cake is delicious, and it makes everything better.</p>",
        "image": "../assets/image/server/otherProduct/salesforceArchitecture.PNG",
        "imageClass": "mx-auto d-block"
      },
      {
        "text": "<p><b>There’s a lot to unpack here, but let’s focus on the most important points.</b><ol><li>Salesforce is a cloud company. Everything we offer resides in the trusted, multitenant cloud.</li><li>The Salesforce platform is the foundation of our services. It’s powered by metadata and made up of different parts, like data services, artificial intelligence, and robust APIs for development.</li><li>All our apps sit on top of the platform. Our prebuilt offerings like Sales Cloud and Marketing Cloud, along with apps you build using the platform, have consistent, powerful functionality.</li><li>Everything is integrated. Our platform technologies like Einstein predictive intelligence and the Lightning framework for development are built into everything we offer and everything you build.</li></ol></p>",
        "image": ""
      },
      {
        "text": "<p><b>Differences Between Salesforce Classic vs Lightning</b><ol><li><b>Enhanced User Experience:</b> One of the major differences between Salesforce Classic and Salesforce Lightning is the user interface. The latter offers a much better user interface experience to its users that includes features like the drag-and-drop functionality that can be achieved without any code. Instead of hiring a Salesforce developer to create a Salesforce page or modify it, the page components can easily be rearranged by an admin according to their liking. <br>Furthermore, Lightning helps in toning down the need for Visualforce for every task. The codes that are created during any kind of development need to be tested and then deployed. In case of missed bugs, the code is sent back to the developer to fix and the process starts over again. But with the help of Salesforce Lightning, these types of tedious processes can be avoided. <br>Lightning does not mean that companies don’t need Visualforce developers anymore. Lightning provides a helping hand to the developers by moving minor customization tasks to the admins, which allows developers to focus on larger Salesforce app development projects.</li><li><b>Higher Security:</b> With Salesforce Lightning comes enhanced security. For instance, LockerService is a feature that separates Lightning components for them to interact with each other. This helps in safeguarding the platform from malicious data. No such feature can be found in the Classic mode.<br>Permissions, too, work quite distinctly in Salesforce Lightning. The platform does not allow users to raise their assurance levels, say from standard to high, in-session. For that, they will have to log out of the Lightning platform and sign in again with authentication with a higher assurance level.</li><li><b>Einstein (Wave) Analytics:</b> While an enhanced and upgraded user interface and security are the points strong enough for the comparison, Salesforce Lightning also provides users with access to Einstein (Wave) Analytics reporting, which the Classic does not. For creating graphs, charts, and lists, the Salesforce Classic reports depend on standard reporting types. At the time the data is refreshed, these dashboards prove to be a great option for capturing a view of important metrics.<br>When we talk about Einstein Analytics, it is a whole different deal. The platform carries its own database that is fetched from Salesforce and updates each hour automatically. Also, the dashboard displays the most recent, refreshed data.</li><li><b>Progressive platform:</b> In its initial days, Lightning was looked down at because of its transition and compatibility issues with objects, custom code, and apps. But gone are those days, and the platform has evolved with the ability to support all custom metadata objects, making it a lot simpler for companies to transition their existing apps and workflows with no requirements of building from scratch.</li><li><b>Hassle-free Lead Generation: </b>Although Salesforce Classic enables you to create leads, the Lightning Experience offers more components in order to manage sales processes better. For instance, the Activity timeline in the Lightning mode allows users to identify what’s been achieved for a specific lead and presents the details of every meeting, task, or call. The Path component enables the tracking of various stages involved in the business process, whereas, the News component offers updates about the leads on time.</li></ol></p>",
        "image": ""
      },
      {
        "text": "<p><b>Aura Components</b><br>Aura components are the self-contained and reusable units of an app. They represent a reusable section of the UI, and can range in granularity from a single line of text to an entire app.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Database in Context of Salesforce</b><br>When we talk about the database, think of a giant spreadsheet. When you put information into Salesforce, it gets stored in the database so you can access it again later. It’s stored in a very specific way so you’re always accessing the information you need.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Metadata</b><br>When you look at data in Salesforce, you might think that you're looking at a user interface sitting on top of a run-of-the-mill relational database. But what you’re actually looking at is an abstraction of the database that’s driven by the platform’s metadata-aware architecture.</p><p>In this abstraction, objects are our database tables. The fields on those objects are columns, and records are rows in the database. This analogy is true both for standard objects that come with Salesforce by default and custom objects that you build yourself.</p><p>In short, metadata forms the structure of your org. Whether you’re defining fields, business processes, or something more complex, metadata holds your configuration. The platform then renders your app’s metadata in the user interface along with its associated data.</p>",
        "image": ""
      },
      {
        "text": "<p><b>No-Code and Low-Code Development</b><br>It can be surprising to hear, but the Salesforce platform encourages you to minimize code. And it’s not because we don’t love code. It’s because the platform’s metadata-driven architecture lets you complete most basic development tasks without ever writing a line.</p><p>Salesforce offers a host of tools for point-and-click—or declarative—development. Most of these tools require little to no understanding of development principles: no code.</p><p>Some development tasks, like writing validation rules or hooking up components with UI elements, are considered low code. That means they require some basic programmatic knowledge to complete, but aren’t so rigorous that they’re considered programmatic. For example, if you know something about logic, conditions, and CRUD operations, you can do more with Process Builder.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Salesforce Security</b><br>The platform makes it easy to specify which users can view, create, edit, or delete any record or field in the app. You can control access to your whole org, a specific object, a specific field, or even an individual record. By combining security controls at different levels, you can provide just the right level of data access to thousands of users without having to specify permissions for each user individually.</p>",
        "image": "../assets/image/server/otherProduct/salesforceSecurity.PNG",
        "imageClass": "mx-auto d-block"
      }
    ]
  },
  {
    "id": 1400,
    "date": "2020/11/22",
    "title": "Salesforce Tools",
    "itemList": [
      {
        "text": "<p><b>Automation Tools</b><p>One of the hardest things for an admin or a developer to figure out is when to use what tool for the job at hand. In general, it’s best to start with declarative, no-code tools and work your way up to code solutions.</p><ul><li><b>Process Builder:</b> Use Process Builder when you need to start a behind-the-scenes business process automatically. Processes can start when:<br><ul><li>A record is created</li><li>A record is updated</li><li>A platform event occurs</li></ul></li><li><b>Flow Builder:</b> Use Flow Builder to:<ul><li>Automate a guided visual experience</li><li>Add more functionality for a behind-the-scenes process than is available in Process Builder. Use Flow Builder to build the more complex functionality. Then call the resulting flow from the process</li><li>Start a behind-the-scenes business process:<ul><li>When a user clicks something, like a button</li><li>When a record is created</li><li>When a record is updated</li><li>When a platform event occurs</li><li>At a specified time and frequency</li></ul></li></ul></li><li><b>Approvals:</b> Approvals isn’t included in Lightning Flow, but it offers a declarative way to automate something that Lightning Flow doesn’t cover. That said, Lightning Flow does support automating how a record gets submitted for approval.</li></ul></p>",
        "image": ""
      },
      {
        "text": "<p><b>Which Automation Tool Is Right for My Use Case?</b><br>When it’s all said and done, a process-driven experience isn’t backed by only one process. It’s a combination of all the business processes in your org that can impact your customer. Each business process typically falls into one of these camps.</p>",
        "image": "../assets/image/server/otherProduct/tools.PNG",
        "imageClass": "mx-auto d-block"
      }
    ]
  },
  {
    "id": 1500,
    "date": "2020/11/24",
    "title": "Salesforce Data Security",
    "itemList": [
      {
        "text": "<p><b>Levels of Data Access</b><p>You can control which users have access to which data in your whole org, a specific object, a specific field, or an individual record.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Organization</b><p>For your whole org, you can maintain a list of authorized users, set password policies, and limit logins to certain hours and locations.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Objects</b><p>Access to object-level data is the simplest thing to control. By setting permissions on a particular type of object, you can prevent a group of users from creating, viewing, editing, or deleting any records of that object. For example, you can use object permissions to ensure that interviewers can view positions and job applications but not edit or delete them.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Fields</b><p>You can restrict access to certain fields, even if a user has access to the object. For example, you can make the salary field in a position object invisible to interviewers but visible to hiring managers and recruiters.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Records</b><p>You can allow particular users to view an object, but then restrict the individual object records they're allowed to see. For example, an interviewer can see and edit her own reviews, but not the reviews of other interviewers. You can manage record-level access in these four ways.</p>",
        "image": ""
      },
      {
        "text": "<p><ul><li><b>Organization-wide defaults</b> specify the default level of access users have to each others’ records. You use org-wide sharing settings to lock down your data to the most restrictive level, and then use the other record-level security and sharing tools to selectively give access to other users.</li><li><b>Role hierarchies</b> give access for users higher in the hierarchy to all records owned by users below them in the hierarchy. Role hierarchies don’t have to match your organization chart exactly. Instead, each role in the hierarchy should represent a level of data access that a user or group of users needs.</li><li><b>Sharing rules</b> are automatic exceptions to organization-wide defaults for particular groups of users, so they can get to records they don’t own or can’t normally see. Sharing rules, like role hierarchies, are only used to give additional users access to records. They can’t be stricter than your organization-wide default settings.</li><li><b>Manual sharing</b> allows owners of particular records to share them with other users. Although manual sharing isn’t automated like org-wide sharing settings, role hierarchies, or sharing rules, it can be useful in some situations, such as when a recruiter going on vacation needs to temporarily assign ownership of a job application to someone else.</li></ul></p>",
        "image": ""
      },
      {
        "text": "<p><b>Manage Object Permissions</b><p>The simplest way to control data access is to set permissions on a particular type of object. (An object is a collection of records, like leads or contacts.) You can control whether a group of users can create, view, edit, or delete any records of that object.</p><p>You can set object permissions with profiles or permission sets. A user can have one profile and many permission sets.<ul><li>A user’s profile determines the objects they can access and the things they can do with any object record (such as create, read, edit, or delete).</li><li>Permission sets grant additional permissions and access settings to a user.</li></ul></p><p>Use profiles to grant the minimum permissions and settings that all users of a particular type need. Then use permission sets to grant more permissions as needed. The combination of profiles and permission sets gives you a great deal of flexibility in specifying object-level access.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Use Profiles to Restrict Access</b><p>Each user has a single profile that controls which data and features that user has access to. A profile is a collection of settings and permissions. Profile settings determine which data the user can see, and permissions determine what the user can do with that data.<ul><li>The settings in a user’s profile determine whether the user can see a particular app, tab, field, or record type.</li><li>The permissions in a user’s profile determine whether the user can create or edit records of a given type, run reports, and customize the app.</li></ul></p><p>Profiles usually match up with a user's job function (for example, system administrator, recruiter, or hiring manager), but you can have profiles for anything that makes sense for your Salesforce org. A profile can be assigned to many users, but a user can have only one profile at a time.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 1600,
    "date": "2020/11/26",
    "title": "Salesforce Dashboard",
    "itemList": [
      {
        "text": "<p>A dashboard is a visual display of key metrics and trends for records in your org. The relationship between a dashboard component and report is 1:1; for each dashboard component, there is a single source report. However, you can use the same report in multiple dashboard components on a single dashboard (for example, use the same report in both a bar chart and pie chart). You can display multiple dashboard components on a single dashboard page, creating a powerful visual display and a way to consume multiple reports that often have a common theme, like sales performance or customer support.</p>",
        "image": ""
      },
      {
        "text": "<p>Like reports, dashboards are stored in folders, which control who has access. If you have access to a folder, you can view its dashboards. However, to view the dashboard components, you need access to the underlying reports as well.</p>",
        "image": ""
      },
      {
        "text": "<p>Each dashboard has a running user, whose security settings determine which data to display in a dashboard. If the running user is a specific user, all dashboard viewers see data based on the security settings of that user—regardless of their own personal security settings. For this reason, you’ll want to choose the running user wisely, so as not to open up too much visibility. For example, set the sales manager as the running user for a leaderboard for her team. This allows her team members to view the leaderboard for their individual team, but not other teams.</p>",
        "image": ""
      },
      {
        "text": "<p>Dynamic dashboards are dashboards for which the running user is always the logged-in user. This way, each user sees the dashboard according to his or her own access level. If you’re concerned about too much access, dynamic dashboards might be the way to go.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 1700,
    "date": "2020/11/28",
    "title": "Salesforce Object",
    "itemList": [
      {
        "text": "<b>Relationships Among Objects</b><p><ul><li>Master-Detail (1:n) — A parent-child relationship in which the master object controls certain behaviors of the detail object.</li><li>Many-to-many — You can use master-detail relationships to model many-to-many relationships between any two objects</li><li>Lookup (1:n) — This type of relationship links two objects together, but has no effect on deletion or security. Unlike master-detail fields, lookup fields are not automatically required. When you define a lookup relationship, data from one object can appear as a custom related list on page layouts for the other object.</li></ul></p>",
        "image": ""
      }
    ]
  },
  {
    "id": 1800,
    "date": "2020/11/28",
    "title": "Salesforce DML",
    "itemList": [
      {
        "text": "<p>Apex contains the built-in Database class, which provides methods that perform DML operations and mirror the DML statement counterparts.</p><p>Unlike DML statements, Database methods have an optional allOrNone parameter that allows you to specify whether the operation should partially succeed. When this parameter is set to false, if errors occur on a partial set of records, the successful records will be committed and errors will be returned for the failed records. Also, no exceptions are thrown with the partial success option.</p>",
        "image": ""
      },
      {
        "text": "<b>Should You Use DML Statements or Database Methods?</b><p><ul><li>Use DML statements if you want any error that occurs during bulk DML processing to be thrown as an Apex exception that immediately interrupts control flow (by using try. . .catch blocks). This behavior is similar to the way exceptions are handled in most database procedural languages.</li><li>Use Database class methods if you want to allow partial success of a bulk DML operation—if a record fails, the remainder of the DML operation can still succeed. Your application can then inspect the rejected records and possibly retry the operation. When using this form, you can write code that never throws DML exception errors. Instead, your code can use the appropriate results array to judge success or failure. Note that Database methods also include a syntax that supports thrown exceptions, similar to DML statements.</li></ul></p>",
        "image": ""
      }
    ]
  },
  {
    "id": 1900,
    "date": "2020/12/11",
    "title": "SOQL",
    "itemList": [
      {
        "text": "<p>Instead of using the equal operator (=) for comparison, you can perform fuzzy matches by using the LIKE operator. For example, you can retrieve all accounts whose names start with SFDC by using this condition: WHERE Name LIKE 'SFDC%'. The % wildcard character matches any or no character. The _ character in contrast can be used to match just one character.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 2000,
    "date": "2020/11/27",
    "title": "Apex",
    "itemList": [
      {
        "text": "<p>Apex is a case-insensitive language.</p><p>Apex is tightly integrated with the database, you can access Salesforce records and their fields directly from Apex. Every record in Salesforce is natively represented as an sObject in Apex.</p>",
        "image": ""
      },
      {
        "text": "<p>Unlike specific sObjects types, generic sObjects can be created only through the newSObject() method. Also, the fields of a generic sObject can be accessed only through the put() and get() methods.</p><p>You can delete persisted records using the delete statement. Deleted records aren’t deleted permanently from Lightning Platform, but they’re placed in the Recycle Bin for 15 days from where they can be restored.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 2100,
    "date": "2020/12/12",
    "title": "Apex Triggers",
    "itemList": [
      {
        "text": "<p>To access the records that caused the trigger to fire, use context variables. For example, Trigger.New contains all the records that were inserted in insert or update triggers. Trigger.Old provides the old version of sObjects before they were updated in update triggers, or a list of deleted sObjects in delete triggers. Triggers can fire when one record is inserted, or when many records are inserted in bulk via the API or Apex. Therefore, context variables, such as Trigger.New, can contain only one record or multiple records. You can iterate over Trigger.New to get each individual sObject.</p>",
        "image": ""
      },
      {
        "text": "<p>The system saves the records that fired the before trigger after the trigger finishes execution. You can modify the records in the trigger without explicitly calling a DML insert or update operation. If you perform DML statements on those records, you get an error.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Trigger Context Variables</b></p>",
        "image": "../assets/image/server/otherProduct/triggerContextVariabe.PNG",
        "imageClass": "mx-auto d-block"
      },
      {
        "text": "<p><b>Triggers and Callouts</b><br>Apex allows you to make calls to and integrate your Apex code with external Web services. Apex calls to external Web services are referred to as callouts. For example, you can make a callout to a stock quote service to get the latest quotes. When making a callout from a trigger, the callout must be done asynchronously so that the trigger process doesn’t block you from working while waiting for the external service's response.The asynchronous callout is made in a background process, and the response is received when the external service returns it.</p><p>To make a callout from a trigger, call a class method that executes asynchronously. Such a method is called a future method and is annotated with @future(callout=true). This example class contains the future method that makes the callout.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 2200,
    "date": "2020/11/29",
    "title": "Apex Test",
    "itemList": [
      {
        "text": "<p>Salesforce records that are created in test methods aren’t committed to the database. They’re rolled back when the test finishes execution. This rollback behavior is handy for testing because you don’t have to clean up your test data after the test executes.</p><p>Whenever you modify your Apex code, rerun your tests to refresh code coverage results.</p><p>A known issue with the Developer Console prevents it from updating code coverage correctly when running a subset of tests. To update your code coverage results, use Test | Run All rather than Test | New Run.</p><p>By default, Apex tests don’t have access to pre-existing data in the org, except for access to setup and metadata objects, such as the User or Profile objects. Set up test data for your tests. Creating test data makes your tests more robust and prevents failures that are caused by missing or changed data in the org. You can create test data directly in your test method, or by using a utility test class as you’ll find out later.</p><p>Even though it is not a best practice to do so, there are times when a test method needs access to pre-existing data. To access org data, annotate the test method with @isTest(SeeAllData=true). The test method examples in this unit don’t access org data and therefore don’t use the SeeAllData parameter.</p>",
        "image": ""
      },
      {
        "text": "<p>The test method contains the Test.startTest() and Test.stopTest() method pair, which delimits a block of code that gets a fresh set of governor limits. In this test, test-data setup uses two DML statements before the test is performed. To test that Apex code runs within governor limits, isolate data setup’s limit usage from your test’s. To isolate the data setup process’s limit usage, enclose the test call within the Test.startTest() and Test.stopTest() block. Also use this test block when testing asynchronous Apex. For more information, see Using Limits, startTest, and stopTest.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 2300,
    "date": "2020/12/13",
    "title": "Visualforce",
    "itemList": [
      {
        "text": "<p>Visualforce is a web development framework that enables developers to build sophisticated, custom user interfaces for mobile and desktop apps that can be hosted on the Lightning Platform. You can use Visualforce to build apps that align with the styling of Lightning Experience, as well as your own completely custom interface. Visualforce enables developers to extend Salesforce’s built-in features, replace them with new functionality, and build completely new apps. Use powerful built-in standard controller features, or write your own custom business logic in Apex. You can build functionality for your own organization, or create apps for sale in the AppExchange.</p>",
        "image": ""
      },
      {
        "text": "<p>Visualforce app development is familiar to anyone who has built web apps. Developers create Visualforce pages by composing components, HTML, and optional styling elements. Visualforce can integrate with any standard web technology or JavaScript framework to allow for a more animated and rich user interface. Each page is accessible by a unique URL. When someone accesses a page the server performs any data processing required by the page, renders the page into HTML, and returns the results to the browser for display. Visualforce request processing overview.</p>",
        "image": ""
      },
      {
        "text": "<p>To see your page in the context of Lightning Experience, return to your main Lightning Experience browser window. Open your browser’s JavaScript console and enter the following code. Don’t forget to replace pageName with your page’s name:<br><code>$A.get('e.force:navigateToURL').setParams({'url':'/apex/HelloWorld'}).fire();</code></p>",
        "image": ""
      },
      {
        "text": "<p><b>Static Resources</b><br>Static resources allow you to upload content that you can reference in a Visualforce page. Resources can be archives (such as .zip and .jar files), images, stylesheets, JavaScript, and other files.Static resources are managed and distributed by Lightning Platform, which acts as a content distribution network (CDN) for the files. Caching and distribution are handled automatically.</p><p>Static resources are referenced using the $Resource global variable, which can be used directly by Visualforce, or used as a parameter to functions such as URLFOR().</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 2400,
    "date": "2020/12/15",
    "title": "Field History Tracking",
    "itemList": [
      {
        "text": "<p>You can select certain fields to track and display the field history in the History related list of an object. Field history data is retained for up to 18 months through your org, and up to 24 months via the API. Field history tracking data doesn’t count against your Salesforce org’s data storage limits.</p>",
        "image": ""
      },
      {
        "text": "<p>Modifying any of these fields adds an entry to the History related list. All entries include the date, time, nature of the change, and who made the change. Not all field types are available for historical trend reporting. Certain changes, such as case escalations, are always tracked.</p>",
        "image": ""
      },
      {
        "text": "<p>Modifying any of these fields adds an entry to the History related list. All entries include the date, time, nature of the change, and who made the change. Not all field types are available for historical trend reporting. Certain changes, such as case escalations, are always tracked.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 2500,
    "date": "2020/12/13",
    "title": "Lightning Components",
    "itemList": [
      {
        "text": "<p>You can use the Developer Console to create Aura components. Using the Developer Console, you can create a component bundle. A component bundle acts like a folder in that it contains components and all other related resources, such as style sheets, controllers, and design.</p>",
        "image": ""
      },
      {
        "text": "<p>Visualforce app development is familiar to anyone who has built web apps. Developers create Visualforce pages by composing components, HTML, and optional styling elements. Visualforce can integrate with any standard web technology or JavaScript framework to allow for a more animated and rich user interface. Each page is accessible by a unique URL. When someone accesses a page the server performs any data processing required by the page, renders the page into HTML, and returns the results to the browser for display. Visualforce request processing overview.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 2600,
    "date": "2020/12/16",
    "title": "Lightning Platform APIs",
    "itemList": [
      {
        "text": "<p>In the sea of Salesforce APIs, there’s a key archipelago of commonly used APIs that we focus on in this module. They are REST API, SOAP API, Bulk API, and Streaming API. Together they make up the Salesforce data APIs. Their purpose is to let you manipulate your Salesforce data, whereas other APIs let you do things like customize page layouts or build custom development tools. You can use other Salesforce APIs to manipulate subsets of your Salesforce data, too. For example, Analytics REST API focuses on Analytics. But these four APIs apply broadly across the spectrum of core Salesforce data.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Rest API</b></p>",
        "image": ""
      },
      {
        "text": "<p><b>SOAP API</b></p>",
        "image": ""
      },
      {
        "text": "<p><b>Bulk API</b><br>Bulk API is a specialized RESTful API for loading and querying lots of data at once. By lots, we mean 50,000 records or more. Bulk API is asynchronous, meaning that you can submit a request and come back later for the results. This approach is the preferred one when dealing with large amounts of data. There are two versions of Bulk API (1.0 and 2.0). Both versions handle large amounts of data, but we use Bulk API 2.0 in this module because it’s a bit easier to use.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Streaming API</b><br>Streaming API is a specialized API for setting up notifications that trigger when changes are made to your data. It uses a publish-subscribe, or pub/sub, model in which users can subscribe to channels that broadcast certain types of data changes.</p><p>The pub/sub model reduces the number of API requests by eliminating the need for polling. Streaming API is great for writing apps that would otherwise need to frequently poll for changes.</p>",
        "image": ""
      },
      {
        "text": "<p>Streaming API is your radar. It lets you define events and push notifications to your client app when the events occur. You don’t have to keep an active lookout for data changes—you don’t have to constantly poll Salesforce and make unnecessary API requests.</p><p>Tracking data changes in Salesforce is especially useful when you have business data stored in a system external to Salesforce. You can use Streaming API to keep your external source in sync with your Salesforce data with PushTopic events and Change Data Capture events. Also, Streaming API lets you process business logic in an external system in response to data changes in Salesforce. For example, you can use Streaming API to notify a fulfillment center whenever an opportunity is updated.</p><p>In addition to data changes, you can use Streaming API to broadcast custom notifications with platform events and generic streaming. For example, an app can generate platform event notifications for orders that an order fulfillment service processes. Or an app can listen to generic events and display a message whenever a system maintenance window is about to start or when a new offer is available to your users.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 2700,
    "date": "2020/12/19",
    "title": "User Interface API",
    "itemList": [
      {
        "text": "<p>The foundation of the Lightning stack is User Interface API, which gives you payloads of Salesforce data and metadata that are structured for building UI. Use your favorite web framework or language to build any custom web or native mobile app that you can imagine. React, Vue, Angular, iOS, Android...if you can make an HTTP request, you can use User Interface API.</p>",
        "image": ""
      },
      {
        "text": "<p>Salesforce has many APIs and it can be difficult to know which is the best tool for the job. If you’re building a custom web or mobile app and need a user interface that lets users view, create, edit, and delete Salesforce records—a user interface that looks and behaves like Salesforce—UI API is the way to go.</p>",
        "image": ""
      },
      {
        "text": "<p>If you’re building a user interface to let users edit dependent picklists and lookups, User Interface API is definitely the way to go. User Interface API has a resource that makes it a whole lot easier.</p>",
        "image": ""
      },
      {
        "text": "<p>Don’t use User Interface API for system integration. Or to create an automated integration for uploading or extracting data. Or to upload or extract data in bulk. Use the Enterprise API or the Bulk API for those tasks.</p>",
        "image": ""
      },
      {
        "text": "<p>If you’re building Lightning components, don’t use UI API directly, use Lightning Data Service (LDS).</p><p>LDS is built on User Interface API, but it also caches responses and updates all records that are affected by the data changes. When you’re working with LDS, you don’t have to worry about making REST calls and caching results, because LDS does it for you. And when data changes, LDS updates all the relevant components. Not only does LDS eliminate inconsistent data between components, it also lets users work offline and syncs the data when they go back online. LDS is cool.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 2800,
    "date": "2020/12/19",
    "title": "Apex Web Services",
    "itemList": [
      {
        "text": "<b>Expose a Class as a REST Service</b><p>Making your Apex class available as a REST web service is straightforward. Define your class as global, and define methods as global static. Add annotations to the class and methods. For example, this sample Apex REST class uses one method. The getRecord method is a custom REST API call. It’s annotated with @HttpGet and is invoked for a GET request.</p>",
        "image": ""
      },
      {
        "text": "<b>Expose a Class as a SOAP Service</b><p>Making your Apex class available as a SOAP web service is as easy as with REST. Define your class as global. Add the webservice keyword and the static definition modifier to each method you want to expose. The webservice keyword provides global access to the method it is added to.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 2900,
    "date": "2020/12/17",
    "title": "Salesforce Tips",
    "itemList": [
      {
        "text": "<p>Salesforce’s Winter ’19 release introduced the amazing <b>‘Where is this used?’ feature</b>. This feature makes it possible for administrators to access Metadata without enabling access to Data. Users can now easily create, edit, and delete Metadata without touching the Data. Users can check references to a custom field, such as Layout or Apex Trigger, by clicking on the ‘Where is this used?’ button.</p>",
        "image": ""
      },
      {
        "text": "------<p>To get all tracked fields on Account you can use:</p><p><code>SELECT QualifiedApiName FROM FieldDefinition WHERE EntityDefinition.QualifiedApiName = 'Account' AND IsFieldHistoryTracked = true</code></p>",
        "image": ""
      },
      {
        "text": "------<p>Use Workbench to Call User Interface API:</p><p><code>/services/data/v48.0/ui-api/object-info</code></p>",
        "image": ""
      },
      {
        "text": "------<p>Use Workbench to fetch a Record:</p><p><code>/services/data/v48.0/ui-api/record-ui/{recordIds}</code></p>",
        "image": ""
      }
    ]
  },
  {
    "id": 3000,
    "date": "2020/12/01",
    "title": "Salesforce Page Layout",
    "itemList": [
      {
        "text": "<p>There are two ways to customize a page in Lightning Experience. You can customize a page’s layout, or customize its contents. These are done with separate tools.</p><p>Lightning pages are a collection of Lightning components arranged in regions on the page. You can customize the structure of the page and the position of its components with the Lightning App Builder (learn more in the Lightning App Builder module right here on Trailhead).</p><p>You can customize a page’s contents, such as the fields and buttons that appear on the page, by using a different tool called the <b>page layout editor</b>. The page layout editor, also known as page layouts, helps you manage the content of pages in both our Classic UI and in Lightning Experience. The page layout editor is what we’ll be working with in this unit.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 3100,
    "date": "2020/12/03",
    "title": "Copado Branch Management",
    "itemList": [
      {
        "text": "<p>If there is no track of metadata changes in the different sandboxes, leverage Copado's Org Differences and Snapshot Differences features to compare the metadata differences between the production org and UAT/int/dev sandboxes.</p><p>Alternatively, the Git Snapshot feature lets you commit the metadata to all your environments to different branches of a Git repository. Once all the metadata in the different environments is committed to the branches, create pull requests between the branches to compare the differences.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Promotions</b><p>When the user story is promoted, Copado creates a promotion branch out of the destination branch. Then the feature branch(es) of the promoted user story(ies) get merged into the promotion branch, with the version of the files as in the feature branch(es), not the source org branch.</p><p>If you are promoting multiple user stories, feature branches get merged in ascending order based on the user story number. If there are overlapped metadata (e.g. 2 or more user stories contain the same Apex Class). Copado will try first a Git merge, but if there is a Git conflict, the feature branch version of the file will win over the promotion branch. This could lead to the last user story overwriting other user stories in the same promotion. This situation can be detected in advance with the overlap awareness feature. If Copado auto-resolves conflicts, you will receive an email with the file name(s) where the conflicts were auto-resolved. You can also review the merge in the promotion branch in the Git repository. You then need to sync the feature branches so that they have the same version of the overlapped file.</p><p>Exclude user stories created in UAT and integration from CBM, to avoid back porting them to the dev sandboxes. You can exclude them by checking the Exclude from CBM checkbox in the user story layout.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Destructive Changes</b><p>Destructive Changes is a Git operation that can be executed from the Git Snapshot and the User Story Commit pages and allows you to remove components both in Git and in your sandboxes. If you want to delete a component in Git and also in the destination sandboxes, you should use this functionality in a user story. If you just want to delete the component in Git,  you can use it in a Git snapshot.</p><p>When you select this operation, you can see the org credential and the metadata grid with the metadata components of the environment related to the org credential selected. If the component does not appear in the grid because it has already been deleted in the source org, then select a different org credential in the lookup field which corresponds to an org that still has the item to be deleted.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 3200,
    "date": "2020/12/04",
    "title": "Copado Org Differences",
    "itemList": [
      {
        "text": "<p>Org differences are calculated based on the last modified dates of the components in the source and destination orgs. To find metadata differences in content, use the Snapshot differences feature instead.</p>",
        "image": ""
      },
      {
        "text": "<p>When calculating org differences, a list of metadata is retrieved for the two orgs, and if the last modified date of a component is greater in the source environment, the component will be flagged as an update. If the last modified date is greater in the destination environment, no 'updated' flag will be shown.</p>",
        "image": ""
      },
      {
        "text": "<p>If a component experienced changes, but these were reverted, this component will appear as an update difference even if the content of the component is the same in both orgs. The last modified date can also be different if the component was deployed to the source org without any content/configuration changes.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 3300,
    "date": "2020/12/04",
    "title": "Copado Continuous Delivery",
    "itemList": [
      {
        "text": "<p>Copado Continuous Delivery makes use of Salesforce’s Change Data Capture (CDC) capability to enable automated and scheduled deployments. If you specify a scheduled or automated deployment behavior, please make sure you have enabled Change Data Capture in the Setup UI for two particular Copado objects: User Story and Promotion.</p>",
        "image": ""
      },
      {
        "text": "<p>It is possible to use Continuous Delivery to allow developers to deploy their work to different environments, even if they don’t have their own org credentials for that particular environment. To do this, simply set a default org credential for these environments. The default org credential will enable Continuous Delivery to deploy user stories to that environment, even if the developer doesn’t have their own access.</p>",
        "image": ""
      },
      {
        "text": "<p>Only someone with the Copado Admin license can deploy to production orgs. If you want to enable Continuous Delivery to automatically deploy certain kinds of user stories to production orgs, someone with a Copado Admin license will need to assign a default org credential to the production org.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Pipeline Page</b><br><ul><li>If the deployment has been successful, you will see a green check.</li><li>If the deployment has failed, a red cross will be displayed.</li><li>If the deployment is still in progress, you will see an in-progress icon.</li><li>If the deployment is waiting for a manual action to be completed, you will see a pause icon.</li><li>If there is a merge conflict you will see a yellow warning icon.</li></ul></p>",
        "image": ""
      },
      {
        "text": "<p>When using the promotion process, Copado combines the metadata (typically configuration) and Git metadata (typically code) to produce one single deployment record which will contain multiple steps.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 3400,
    "date": "2020/12/05",
    "title": "Copado Git Operations",
    "itemList": [
      {
        "text": "<p><b>Commit Files:</b> The Commit Files operation is available in the Git Snapshot and the User Story Commit pages. This operation allows you to commit specific metadata components of an org into a Git branch. You can use it to select new components that have not yet been committed in a user story or to commit an update in components that have been previously committed.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Recommit Files:</b> The Recommit Files operation is available in the User Story Commit page. This operation allows you to commit previously committed changes. When this operation is selected, all the components that have been previously selected and committed in the user story (User Story Selections) are automatically selected in the metadata grid, allowing you to speed up the process of updating your feature branch with the newest content in your org.</p><p>Additionally, if you have committed something wrong and want to get rid of the selection, this operation allows you to recreate the feature branch by checking the Re-create Feature Branch checkbox.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Destructive Changes:</b> The Destructive Changes operation is available in the Git Snapshot and the User Story Commit pages. This operation allows you to remove components both in Git and in your sandboxes.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Full Profiles & Permission Sets:</b> The Full Profiles & Permission Sets operation is available in the User Story Commit page. This operation allows you to commit full profiles and permission sets from one source org into Git. You should only use this operation for profiles and permission sets that are new and don't exist in the repository as the file will be overriding any other changes if a conflict is found.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Retrieve Only</b><br>With the Retrieve Only checkbox you will be able to pull OLS/FLS for profiles and permission sets, without having to commit/deploy the original fields or objects.<p>This feature gives you a more granular control over profiles and permission sets in regard to objects and fields permissions.</p></p>",
        "image": ""
      }
    ]
  },
  {
    "id": 3500,
    "date": "2020/12/05",
    "title": "Simple and Parent Metadata Types",
    "itemList": [
      {
        "text": "<p>A simple metadata type is a metadata component that represents one file in Git (1:1), such as an ApexClass, an ApexTrigger, an ApexPage or an ApexComponent, for instance. The majority of metadata types fall within this category, so there is no need to list them all. If a metadata type is not included in the parent list or Special Cases section below, it is a simple metadata type.</p>",
        "image": ""
      },
      {
        "text": "<p>A parent metadata type is that where a metadata component represents one file in Git (1:1), but that component contains other nested components. Find below a table with all the parent metadata types and their corresponding nested components:</p>",
        "image": "../assets/image/server/otherProduct/parentMetadataType.PNG",
        "imageClass": "mx-auto d-block"
      },
      {
        "text": "<p><b>Profile</b><br><ul><li>When you commit a profile, only user permissions are included in the profile unless you select other components as well. To deploy the Field Level Security of a field, for example, you have to select the profile together with the field in the same selection, the same commit. The same applies to tab visibility, where you have to include the CustomTab to get the visibility of that tab.</li><li>The most typical metadata component updates in a profile are CustomObject, CustomField, CustomTab, Layout, RecordType, ApexClass, ApexPage, CustomApplication, CustomPermission, and HomePageLayout.</li><li>Copado will merge the retrieved permissions into the profile in Git, unless you commit a full profile, in which case the file in the feature branch will overwrite the file in the promotion branch.</li><li>When committing files, if you select the Retrieve Only checkbox for custom objects, custom fields and page layouts, you will be able to pull OLS/FLS/Layout Assignment without having to commit/deploy the original field/object/layout files. Check out the article User Stories - Git Metadata to get more information.</li></ul></p>",
        "image": ""
      },
      {
        "text": "<p><b>Permission Set</b><br><ul><li>Permission sets behave in the same way as profiles, only permissions for other selected metadata components will be included.</li><li>Copado will merge the retrieved permissions into the permission set in Git, unless you commit a full permission set, in which case the permission set file in the feature branch will overwrite the file in the promotion branch.</li><li>You can select the Retrieve Only checkbox for custom objects and custom fields to pull OLS/FLS without having to commit/deploy the original field/object files. Check out the article User Stories - Git Metadata to get more information.</li></ul></p>",
        "image": ""
      },
      {
        "text": "<p><b>Custom Object</b><br>In contrast to the standard behavior of the metadata API, when you commit a custom object only the attributes are committed, unless you select other components as well. This applies to new and existing custom objects.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Custom Object Translation</b><br>Custom object translations are handled as nested components. Let’s say you want to commit the custom object translation of a field and you just commit that field together with the translation. By doing this, Copado will only update the translation of that field in the destination, and no other field translations will be committed or merged.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Flow</b><br>Deploying a Process Builder Flow in Copado is a seamless process.You can deploy a flow that is active in the source org, and the flow will be activated automatically in the destination org. You can commit an active flow to your repository and deploy from the commit. Check out the article Process Builder Flows to get more information.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Flow Definition</b><br>A FlowDefinition can only be deployed if the flow already exists in the destination. In order to make a deployment not repeatable, the recommendation is not to include this in the source control system (Git) by adding it to your .gitignore file.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Important Considerations</b><br><ul><li>A feature branch will only be created if the metadata retrieved is different from the repository version.</li><li>If a feature branch already exists, and the metadata retrieved is different, the new version will be added to the feature branch. If there are no changes, Git does not produce a commit ID and Copado will show the status No changes.</li><li>If the feature branch does not exist and the metadata selected to be committed has no changes, the feature branch will not be pushed to your repository, and as a consequence, the branch will not exist in your repository.</li><li>As part of the Update User Story selections action, Copado upserts some other auxiliary records and fields such as Git commits and metadata types in selections.</li></ul></p>",
        "image": ""
      }
    ]
  },
  {
    "id": 3600,
    "date": "2020/12/05",
    "title": "Copado Validating Commits",
    "itemList": [
      {
        "text": "<p>From the Commit Changes page, Copado allows you to perform a validation deployment before actually committing the changes into Git.</p><p>The process in order to have this functionality working:</p><p><ul><li>Include in the commit message the following pattern: @validatecommit.</li><li>This command will create the validation deployment without committing any changes into the repository.</li><li>If the deployment is successful, the commit will be executed.</li><li>The validation of a commit relays on a validation deployment in the destination org with the selected metadata components selected in the commit changes action.</li></ul></p>",
        "image": ""
      },
      {
        "text": "<p>Recommit Files: The Recommit Files operation is available in the User Story Commit page. This operation allows you to commit previously committed changes. When this operation is selected, all the components that have been previously selected and committed in the user story (User Story Selections) are automatically selected in the metadata grid, allowing you to speed up the process of updating your feature branch with the newest content in your org.</p><p>Additionally, if you have committed something wrong and want to get rid of the selection, this operation allows you to recreate the feature branch by checking the Re-create Feature Branch checkbox.</p>",
        "image": ""
      },
      {
        "text": "<p>Destructive Changes: The Destructive Changes operation is available in the Git Snapshot and the User Story Commit pages. This operation allows you to remove components both in Git and in your sandboxes.</p>",
        "image": ""
      },
      {
        "text": "<p>Full Profiles & Permission Sets: The Full Profiles & Permission Sets operation is available in the User Story Commit page. This operation allows you to commit full profiles and permission sets from one source org into Git. You should only use this operation for profiles and permission sets that are new and don't exist in the repository as the file will be overriding any other changes if a conflict is found.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 3700,
    "date": "2020/12/06",
    "title": "Manual Task deployment",
    "itemList": [
      {
        "text": "<p>To create a Manual Task deployment, follow these steps:</p><p><ul><li>Navigate to the Deployments tab to create a new Advanced (multi-step) deployment.</li><li>Give your deployment a name and select a source and a destination organization.</li><li>Add a new step and select Manual Task as step type.</li><li>Optionally, add a task owner and select how you want this user to be notified, via chatter, via email or both.</li><li>When Copado reaches a Manual Task deployment step, the deployment process is stopped until the manual task is completed. The task owner will receive a notification for the task to be executed. Once the task is set to Complete, the deployment process will automatically resume</li></ul></p>",
        "image": ""
      }
    ]
  },
  {
    "id": 3800,
    "date": "2020/12/07",
    "title": "Copado Dynamic Variables",
    "itemList": [
      {
        "text": "<p>A variable is a container that stores a piece of data. Variables can be used in a variety of cases, for instance, if you are deploying users to different environments and you want to make sure the email address is the correct one in each environment, or if you are working with Salesforce Flow deployment steps.</p><p>When working with a Salesforce Flow deployment step, Copado provides the following predefined dynamic variables:</p>",
        "image": "../assets/image/server/otherProduct/dynamicVariables.PNG",
        "imageClass": "mx-auto d-block"
      }
    ]
  },
  {
    "id": 5000,
    "date": "2020/12/07",
    "title": "Copado Features vs. Epics",
    "itemList": [
      {
        "text": "<p>Epics typically define the details of an MVP (Minimum Viable Product) and have a limited scope which could span across multiple sprints but are confined to a single release. Epics have no defined start or end date but do have defined scope. Epics can be written as larger user stories and should include the Who, What , and Why. Features are much smaller than epics and can live forever as features may evolve with the product’s lifecycle. Features capture the business value and impact. Features should be developed within a single release, but can live beyond releases and sprints.</p>",
        "image": ""
      }
    ]
  }
]