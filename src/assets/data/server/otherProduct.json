[
  {
    "id": 200,
    "date": "2019/01/03",
    "title": "Jenkins",
    "itemList": [
      {
        "text": "<p>Jenkins is an open source automation server written in Java. Jenkins helps to automate the non-human part of the software development process, with continuous integration and facilitating technical aspects of continuous delivery. It is a server-based system that runs in servlet containers such as Apache Tomcat. It supports version control tools, including AccuRev, CVS, Subversion, Git, Mercurial, Perforce, TD/OMS, ClearCase and RTC, and can execute Apache Ant, Apache Maven and sbt based projects as well as arbitrary shell scripts and Windows batch commands.</p><p>Jenkins can be installed through native system packages, Docker, or even run standalone by any machine with a Java Runtime Environment (JRE) installed.</p>",
        "image": ""
      },
      {
        "text": "<p>Jenkins initial admin password is stored in <code>/var/lib/jenkins/secrets/initialAdminPassword</code> on Linux.</p>",
        "image": ""
      },
      {
        "text": "<p>To check Jenkins status on Linux: <code>service jenkins status</code></p>",
        "image": ""
      },
      {
        "text": "Builds can be triggered by various means, for example by commit in a version control system, by scheduling via a cron-like mechanism and by requesting a specific build URL. It can also be triggered after the other builds in the queue have completed. Jenkins functionality can be extended with plugins.",
        "image": ""
      },
      {
        "text": "<b>Jenkins Pipeline</b><br/><p>Jenkins Pipeline (or simply 'Pipeline') is a suite of plugins which supports implementing and integrating continuous delivery pipelines into Jenkins.<p>A continuous delivery pipeline is an automated expression of your process for getting software from version control right through to your users and customers.</p><p>Jenkins Pipeline provides an extensible set of tools for modeling simple-to-complex delivery pipelines 'as code'. The definition of a Jenkins Pipeline is typically written into a text file (called a Jenkinsfile) which in turn is checked into a project’s source control repository.</p><p>Figure below shows a diagram of all the sections you can have in a Declarative Pipeline. The way to read this chart is that items with solid line borders are required, and items with dotted line borders are optional:</p>",
        "image": "../assets/image/it/tool/jenkinsPipeline.png",
        "imageClass": "mx-auto d-block"
      }
    ]
  },
  {
    "id": 300,
    "date": "2019/01/06",
    "title": "Gira",
    "itemList": [
      {
        "text": "<p>Jira is a proprietary issue tracking product developed by Atlassian that allows bug tracking and agile project management.</p>",
        "image": ""
      },
      {
        "text": "<p>For remote procedure calls (RPC), Jira supports REST, SOAP, and XML-RPC. Jira integrates with source control programs such as Clearcase, Concurrent Versions System (CVS), Git, Mercurial, Perforce, Subversion, and Team Foundation Server.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 400,
    "date": "2019/03/17",
    "title": "Dataweave",
    "itemList": [
      {
        "text": "<p><b>DataWeave Types</b><br/>DataWeave functions operate on data of many types, including <ul><li>Arrays</li><li>Booleans</li><li>CData</li><li>Date and Time</li><li>Enum</li><li>Iterator</li><li>Number</li><li>Object</li><li>Regex</li><li>String</li><li>TryResult</li></ul>The types that DataWeave provide are bundled into modules that also contain the related functions.</p>",
        "image": ""
      },
      {
        "text": "",
        "image": ""
      }
    ]
  },
  {
    "id": 500,
    "date": "2020/03/10",
    "title": "Autosys",
    "itemList": [
      {
        "text": "<p>Autosys is used to start Java process, takes backup of log files, stop Java process, cleaning and purging database and will all sort of housekeeping jobs in Linux environment. Autosys system is made of Autosys server and Autosys clients, each server or box, which has services scheduled by autosys, requires autosys client to be install on that. One of the key advantages of Autosys is that one job can depend upon another job, and can execute, depending upon, success and failure of parent job. Though Java developers are not asked a lot of interview questions, you might expect few of them during your interview with Wall Street banks, Brokers or Financial Institution, which uses autosys.</p>",
        "image": ""
      },
      {
        "text": "<p><b>Autosys Job Status</b></p><p><ul><li>STARTING</li><li>RUNNING</li><li>INACTIVE</li><li>ACTIVATED</li><li>SUCCESS</li><li>FAILURE</li><li>TERMINATED</li><li>RESTART</li><li>QUE_WAIT</li><li>ON HOLD</li><li>ON ICE</li></ul></p>",
        "image": "../assets/image/it/tool/onHoldvsOnIce.png",
        "imageClass": "mx-auto d-block"
      },
      {
        "text": "<p><b>Commands</b></p><p><ul><li><code>sendevent -E STARTJOB -J <i>job_name</i></code></li></p>",
        "image": ""
      }
    ]
  },
  {
    "id": 600,
    "date": "2019/11/30",
    "title": "Api Gateway",
    "itemList": [
      {
        "text": "<p>An API Gateway is a server that is the single entry point into the system. It is similar to the Facade pattern from object-oriented design. The API Gateway encapsulates the internal system architecture and provides an API that is tailored to each client. It might have other responsibilities such as authentication, monitoring, load balancing, caching, request shaping and management, and static response handling.</p><p>The following diagram shows how an API Gateway typically fits into the architecture:</p>",
        "image": "../assets/image/server/web/gateway.png",
        "imageHeight": "450",
        "imageWidth": "800"
      },
      {
        "text": "<p>A gateway helps to address these issues by decoupling clients from services. Gateways can perform a number of different functions, and you may not need all of them. The functions can be grouped into the following design patterns:</p><p>Gateway Routing. Use the gateway as a reverse proxy to route requests to one or more backend services, using layer 7 routing. The gateway provides a single endpoint for clients, and helps to decouple clients from services.</p><p>Gateway Aggregation. Use the gateway to aggregate multiple individual requests into a single request. This pattern applies when a single operation requires calls to multiple backend services. The client sends one request to the gateway. The gateway dispatches requests to the various backend services, and then aggregates the results and sends them back to the client. This helps to reduce chattiness between the client and the backend.</p><p>Gateway Offloading. Use the gateway to offload functionality from individual services to the gateway, particularly cross-cutting concerns. It can be useful to consolidate these functions into one place, rather than making every service responsible for implementing them. This is particularly true for features that requires specialized skills to implement correctly, such as authentication and authorization.</p><p>Here are some examples of functionality that could be offloaded to a gateway:<ul><li>SSL termination</li><li>Authentication</li><li>IP whitelisting</li><li>Client rate limiting (throttling)</li><li>Logging and monitoring</li><li>Response caching</li><li>Web application firewall</li><li>GZIP compression</li><li>Servicing static content</li></ul></p>",
        "image": ""
      },
      {
        "text": "<b>Choosing a gateway technology</b><p>Here are some options for implementing an API gateway in your application.<ul><li><b>Reverse proxy server</b>. Nginx and HAProxy are popular reverse proxy servers that support features such as load balancing, SSL, and layer 7 routing. They are both free, open-source products, with paid editions that provide additional features and support options. Nginx and HAProxy are both mature products with rich feature sets and high performance. You can extend them with third-party modules or by writing custom scripts in Lua. Nginx also supports a JavaScript-based scripting module called NginScript.</li><li><b>Service mesh ingress controller</b>. If you are using a service mesh such as linkerd or Istio, consider the features that are provided by the ingress controller for that service mesh. For example, the Istio ingress controller supports layer 7 routing, HTTP redirects, retries, and other features.</li><li><b>Azure Application Gateway</b>. Application Gateway is a managed load balancing service that can perform layer-7 routing and SSL termination. It also provides a web application firewall (WAF). Application Gateway and Web Application Firewall (WAF) are also available under a Standard_v2 and WAF_v2 SKU. The v2 SKU offers performance enhancements and adds support for critical new features like autoscaling, zone redundancy, and support for static VIPs. Existing features under the Standard and WAF SKU continue to be supported in the new v2 SKU. The new v2 SKU includes the following enhancements:<ul><li>Autoscaling</li><li>Zone redundancy</li><li>Static VIP</li><li>Header Rewrite</li><li>Key Vault Integration</li><li>Azure Kubernetes Service Ingress Controller</li><li>Performance enhancements</li><li>Faster deployment and update time</li></ul></li><li><b>Azure API Management</b>. API Management is a turnkey solution for publishing APIs to external and internal customers. It provides features that are useful for managing a public-facing API, including rate limiting, IP white listing, and authentication using Azure Active Directory or other identity providers. API Management doesn't perform any load balancing, so it should be used in conjunction with a load balancer such as Application Gateway or a reverse proxy. For information about using API Management with Application Gateway, see Integrate API Management in an internal VNet with Application Gateway.</li></ul></p>",
        "image": ""
      }
    ]
  },
  {
    "id": 700,
    "date": "2020/07/09",
    "title": "RabbitMQ",
    "itemList": [
      {
        "text": "<p>With tens of thousands of users, RabbitMQ is one of the most popular open source message brokers. RabbitMQ is lightweight and easy to deploy on premises and in the cloud. It supports multiple messaging protocols. RabbitMQ can be deployed in distributed and federated configurations to meet high-scale, high-availability requirements.</p>",
        "image": ""
      },
      {
        "text": "<p>use <code>rabbitmq-plugins enable rabbitmq_management</code> to enable UI</p>",
        "image": ""
      },
      {
        "text": "<p>use <code>rabbitmqctl status</code> to get status</p>",
        "image": ""
      },
      {
        "text": "<p>connect to RabbitMQ UI using http://localhost:15672/ (default user/password: guest/guest)</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 800,
    "date": "2020/07/10",
    "title": "Kafka",
    "itemList": [
      {
        "text": "<p>Apache Kafka® is a distributed streaming platform. It has three key capabilities:<ul><li>Publish and subscribe to streams of records, similar to a message queue or enterprise messaging system.</li><li>Store streams of records in a fault-tolerant durable way.</li><li>Process streams of records as they occur.</li></ul></p>",
        "image": "../assets/image/server/otherProduct/kafka.PNG",
        "imageClass": "mx-auto d-block"
      },
      {
        "text": "<p>Change to kafka base directory, and use <code>.\\bin\\windows\\zookeeper-server-start.bat .\\config\\zookeeper.properties</code> to start the zookeeper</p>",
        "image": ""
      },
      {
        "text": "<p>Change to kafka base directory, and use <code>.\\bin\\windows\\kafka-server-start.bat .\\config\\server.properties</code> to start the kafka server</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 900,
    "date": "2020/07/15",
    "title": "Informatica",
    "itemList": [
      {
        "text": "<p>INFORMATICA is a Software development company, which offers data integration products. It offers products for ETL, data masking, data Quality, data replica, data virtualization, master data management, etc. Informatica Powercenter ETL/Data Integration tool is the most widely used tool and in the common term when we say Informatica, it refers to the Informatica PowerCenter tool for ETL.</p>",
        "image": "../assets/image/server/otherProduct/informaticaBI.PNG",
        "imageClass": "mx-auto d-block"
      },
      {
        "text": "<p>Informatica Powercenter is used for Data integration. It offers the capability to connect & fetch data from different heterogeneous source and processing of data. For example, you can connect to an SQL Server Database and Oracle Database both and can integrate the data into a third system.</p>",
        "image": "../assets/image/server/otherProduct/informaticaPowerCenter.PNG",
        "imageClass": "mx-auto d-block"
      },
      {
        "text": "<p>INFORMATICA Powercenter has four components: Repository Manager, DEsigner, Workflow Manager, Workflow Monitor.</p>",
        "image": "../assets/image/server/otherProduct/informatica.PNG",
        "imageClass": "mx-auto d-block"
      }
    ]
  },
  {
    "id": 1000,
    "date": "2020/10/20",
    "title": "Mulesoft",
    "itemList": [
      {
        "text": "<p>A Mule event contains the core information processed by the runtime. It travels through components inside your Mule app following the configured application logic.</p><p>Note that the Mule event is immutable, so every change to an instance of a Mule event results in the creation of a new instance.</p><p>A Mule event is generated when a trigger (such as an HTTP request or a change to a database or file) reaches the Event source of a flow. This trigger could be an external event triggered by a resource that might be external to the Mule app.</p>",
        "image": "../assets/image/server/otherProduct/mulesoftEvent.PNG",
        "imageClass": "mx-auto d-block"
      }
    ]
  },
  {
    "id": 1200,
    "date": "2020/10/20",
    "title": "Anypoint Platform CLI",
    "itemList": [
      {
        "text": "<p>Prerequisites:<ul><li>NodeJS and npm</li><li>Git</li><ul></p>",
        "image": ""
      },
      {
        "text": "<p>Installation: <code>npm install -g anypoint-cli@latest</code></p>",
        "image": ""
      },
      {
        "text": "<p>Usage: <code>anypoint-cli --username yupinggaogmail</code></p>",
        "image": ""
      }
    ]
  }
]