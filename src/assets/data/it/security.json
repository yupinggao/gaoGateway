[
  {
    "id": 5,
    "date": "2017/10/15",
    "title": "Overview",
    "itemList": [
      {
        "text": "<b>1. Introduction:</b><p>The Java™ platform was designed with a strong emphasis on security. At its core, the Java language itself is type-safe and provides automatic garbage collection, enhancing the robustness of application code. A secure class loading and verification mechanism ensures that only legitimate Java code is executed.</p><p>The initial version of the Java platform created a safe environment for running potentially untrusted code, such as Java applets downloaded from a public network. As the platform has grown and widened its range of deployment, the Java security architecture has correspondingly evolved to support an increasing set of services. Today the architecture includes a large set of application programming interfaces (APIs), tools, and implementations of commonly-used security algorithms, mechanisms, and protocols. This provides the developer a comprehensive security framework for writing applications, and also provides the user or administrator a set of tools to securely manage applications.</p><p>The Java security APIs span a wide range of areas. Cryptographic and public key infrastructure (PKI) interfaces provide the underlying basis for developing secure applications. Interfaces for performing authentication and access control enable applications to guard against unauthorized access to protected resources.</p><p>The APIs allow for multiple interoperable implementations of algorithms and other security services. Services are implemented in providers, which are plugged into the Java platform via a standard interface that makes it easy for applications to obtain security services without having to know anything about their implementations. This allows developers to focus on how to integrate security into their applications, rather than on how to actually implement complex security mechanisms.</p><p>The Java platform includes a number of providers that implement a core set of security services. It also allows for additional custom providers to be installed. This enables developers to extend the platform with new security mechanisms.</p><p>This paper gives a broad overview of security in the Java platform, from secure language features to the security APIs, tools, and built-in provider services, highlighting key packages and classes where applicable. Note that this paper is based on Java™ SE version 8.</p>",
        "image": ""
      },
      {
        "text": "<b>2. Java Language Security and Bytecode Verification</b><p>The Java language is designed to be type-safe and easy to use. It provides automatic memory management, garbage collection, and range-checking on arrays. This reduces the overall programming burden placed on developers, leading to fewer subtle programming errors and to safer, more robust code.</p><p>In addition, the Java language defines different access modifiers that can be assigned to Java classes, methods, and fields, enabling developers to restrict access to their class implementations as appropriate. Specifically, the language defines four distinct access levels: private, protected, public, and, if unspecified, package. The most open access specifier is public access is allowed to anyone. The most restrictive modifier is private access is not allowed outside the particular class in which the private member (a method, for example) is defined. The protected modifier allows access to any subclass, or to other classes within the same package. Package-level access only allows access to classes within the same package.</p><p>A compiler translates Java programs into a machine-independent bytecode representation. A bytecode verifier is invoked to ensure that only legitimate bytecodes are executed in the Java runtime. It checks that the bytecodes conform to the Java Language Specification and do not violate Java language rules or namespace restrictions. The verifier also checks for memory management violations, stack underflows or overflows, and illegal data typecasts. Once bytecodes have been verified, the Java runtime prepares them for execution.</p>",
        "image": ""
      },
      {
        "text": "<b>3. Basic Security Architecture</b><p>The Java platform defines a set of APIs spanning major security areas, including cryptography, public key infrastructure, authentication, secure communication, and access control. These APIs allow developers to easily integrate security into their application code. They were designed around the following principles:<ul><li><b>Implementation independence:</b> Applications do not need to implement security themselves. Rather, they can request security services from the Java platform. Security services are implemented in providers (see below), which are plugged into the Java platform via a standard interface. An application may rely on multiple independent providers for security functionality.</li><li><b>Implementation interoperability:</b> Providers are interoperable across applications. Specifically, an application is not bound to a specific provider, and a provider is not bound to a specific application.</li><li><b>Algorithm extensibility:</b> The Java platform includes a number of built-in providers that implement a basic set of security services that are widely used today. However, some applications may rely on emerging standards not yet implemented, or on proprietary services. The Java platform supports the installation of custom providers that implement such services.</li><li><b>Security Providers:</b> The java.security.Provider class encapsulates the notion of a security provider in the Java platform. It specifies the provider's name and lists the security services it implements. Multiple providers may be configured at the same time, and are listed in order of preference. When a security service is requested, the highest priority provider that implements that service is selected.</li><li><b>File Locations:</b> Certain aspects of Java security mentioned in this paper, including the configuration of providers, may be customized by setting security properties. You may set security properties statically in the security properties file, which by default is the java.security file in the lib/security directory of the directory where the Java™ Runtime Environment (JRE) is installed. Security properties may also be set dynamically by calling appropriate methods of the Security class (in the java.security package).</p><p>The tools and commands mentioned in this paper are all in the ~jre/bin directory, where ~jre stands for the directory in which the JRE is installed. The cacerts file mentioned in Section 5 is in ~jre/lib/security.</li></ul></p><p align='center'>Classes Related to Java Security</p>",
        "image": "../assets/image/it/security/classes.jpg"
      }
    ]
  },
  {
    "id": 10,
    "date": "2017/10/15",
    "title": "Java Cryptography Architecture (JCA)",
    "itemList": [
      {
        "text": "The Java cryptography architecture is a framework for accessing and developing cryptographic functionality for the Java platform. It includes APIs for a large variety of cryptographic services, including: <ul><li>Message digest algorithms</li><li>Digital signature algorithms</li><li>Symmetric bulk encryption</li><li>Symmetric stream encryption</li><li>Asymmetric encryption</li><li>Password-based encryption (PBE)</li><li>Elliptic Curve Cryptography (ECC)</li><li>Key agreement algorithms</li><li>Key generators</li><li>Message Authentication Codes (MACs)</li><li>(Pseudo-)random number generators</li></ul>",
        "image": ""
      },
      {
        "text": "For historical (export control) reasons, the cryptography APIs are organized into two distinct packages. The java.security package contains classes that are not subject to export controls (like Signature and MessageDigest). The javax.crypto package contains classes that are subject to export controls (like Cipher and KeyAgreement).<p>The cryptographic interfaces are provider-based, allowing for multiple and interoperable cryptography implementations. Some providers may perform cryptographic operations in software; others may perform the operations on a hardware token (for example, on a smartcard device or on a hardware cryptographic accelerator). Providers that implement export-controlled services must be digitally signed.<p>The Java platform includes built-in providers for many of the most commonly used cryptographic algorithms, including the RSA, DSA, and ECDSA signature algorithms, the DES, AES, and ARCFOUR encryption algorithms, the MD5, SHA-1, and SHA-256 message digest algorithms, and the Diffie-Hellman and ECDH key agreement algorithms. These default providers implement cryptographic algorithms in Java code.<p>The Java platform also includes a built-in provider that acts as a bridge to a native PKCS#11 (v2.x) token. This provider, named SunPKCS11, allows Java applications to seamlessly access cryptographic services located on PKCS#11-compliant tokens.<p>On Windows, the Java platform includes a built-in provider that acts as a bridge to the native Microsoft CryptoAPI. This provider, named SunMSCAPI, allows Java applications to seamlessly access cryptographic services on Windows through the CryptoAPI.",
        "image": ""
      },
      {
        "text": "<b>Public Key Infrastructure:</b><p>Public Key Infrastructure (PKI) is a term used for a framework that enables secure exchange of information based on public key cryptography. It allows identities (of people, organizations, etc.) to be bound to digital certificates and provides a means of verifying the authenticity of certificates. PKI encompasses keys, certificates, public key encryption, and trusted Certification Authorities (CAs) who generate and digitally sign certificates.<p>The Java platform includes APIs and provider support for X.509 digital certificates and Certificate Revocation Lists (CRLs), as well as PKIX-compliant certification path building and validation. The classes related to PKI are located in the java.security and java.security.cert packages.",
        "image": ""
      },
      {
        "text": "<b>Key and Certificate Storage:</b><p>The Java platform provides for long-term persistent storage of cryptographic keys and certificates via key and certificate stores. Specifically, the java.security.KeyStore class represents a key store, a secure repository of cryptographic keys and/or trusted certificates (to be used, for example, during certification path validation), and the java.security.cert.CertStore class represents a certificate store, a public and potentially vast repository of unrelated and typically untrusted certificates. A CertStore may also store CRLs.<p>KeyStore and CertStore implementations are distinguished by types. The Java platform includes the standard PKCS11 and PKCS12 key store types (whose implementations are compliant with the corresponding PKCS specifications from RSA Security). It also contains a proprietary file-based key store type called JKS (which stands for 'Java Key Store'), and a type called DKS ('Domain Key Store') which is a collection of keystores that are presented as a single logical keystore.<p>The Java platform includes a special built-in JKS key store, cacerts, that contains a number of certificates for well-known, trusted CAs. The keytool utility is able to list the certificates included in cacerts (see the security features documentation link in Section 10).<p>The SunPKCS11 provider mentioned in the 'Cryptography' section (Section 4) includes a PKCS11 KeyStore implementation. This means that keys and certificates residing in secure hardware (such as a smartcard) can be accessed and used by Java applications via the KeyStore API. Note that smartcard keys may not be permitted to leave the device. In such cases, the java.security.Key object reference returned by the KeyStore API may simply be a reference to the key (that is, it would not contain the actual key material). Such a Key object can only be used to perform cryptographic operations on the device where the actual key resides.<p>The Java platform also includes an LDAP certificate store type (for accessing certificates stored in an LDAP directory), as well as an in-memory Collection certificate store type (for accessing certificates managed in a java.util.Collection object).",
        "image": ""
      },
      {
        "text": "<b>PKI Tools:</b><p>There are two built-in tools for working with keys, certificates, and key stores: keytool and jarsigner.<p>keytool is used to create and manage key stores. It can:<ul><li>Create public/private key pairs</li><li>Display, import, and export X.509 v1, v2, and v3 certificates stored as files</li><li>Create self-signed certificates</li><li>Issue certificate (PKCS#10) requests to be sent to CAs</li><li>Create certificates based on certificate requests</li><li>Import certificate replies (obtained from the CAs sent certificate requests)</li><li>Designate public key certificates as trusted</li><li>Accept a password and store it securely as a secret key</li></ul><p>The jarsigner tool is used to sign JAR files, or to verify signatures on signed JAR files. The Java ARchive (JAR) file format enables the bundling of multiple files into a single file. Typically a JAR file contains the class files and auxiliary resources associated with applets and applications. When you want to digitally sign code, you first use keytool to generate or import appropriate keys and certificates into your key store (if they are not there already), then use the jar tool to place the code in a JAR file, and finally use the jarsigner tool to sign the JAR file. The jarsigner tool accesses a key store to find any keys and certificates needed to sign a JAR file or to verify the signature of a signed JAR file. Note: jarsigner can optionally generate signatures that include a timestamp. Systems (such as Java Plug-in) that verify JAR file signatures can check the timestamp and accept a JAR file that was signed while the signing certificate was valid rather than requiring the certificate to be current. (Certificates typically expire annually, and it is not reasonable to expect JAR file creators to re-sign deployed JAR files annually.)",
        "image": ""
      },
      {
        "text": "<b>Authentication:</b><p>Authentication is the process of determining the identity of a user. In the context of the Java runtime environment, it is the process of identifying the user of an executing Java program. In certain cases, this process may rely on the services described in the 'Cryptography' section (Section 4).<p>The Java platform provides APIs that enable an application to perform user authentication via pluggable login modules. Applications call into the LoginContext class (in the javax.security.auth.login package), which in turn references a configuration. The configuration specifies which login module (an implementation of the javax.security.auth.spi.LoginModule interface) is to be used to perform the actual authentication.<p>Since applications solely talk to the standard LoginContext API, they can remain independent from the underlying plug-in modules. New or updated modules can be plugged in for an application without having to modify the application itself. Figure 3 illustrates the independence between applications and underlying login modules:",
        "image": "../assets/image/it/security/authentication.jpg"
      }
    ]
  },
  {
    "id": 20,
    "date": "2017/10/15",
    "title": "Secure Communication",
    "itemList": [
      {
        "text": "<b>SSL/TLS:</b><p>The Java platform provides APIs and an implementation of the SSL and TLS protocols that includes functionality for data encryption, message integrity, server authentication, and optional client authentication. Applications can use SSL/TLS to provide for the secure passage of data between two peers over any application protocol, such as HTTP on top of TCP/IP.<p>The javax.net.ssl.SSLSocket class represents a network socket that encapsulates SSL/TLS support on top of a normal stream socket (java.net.Socket). Some applications might want to use alternate data transport abstractions (e.g., New-I/O); the javax.net.ssl.SSLEngine class is available to produce and consume SSL/TLS packets.<p>The Java platform also includes APIs that support the notion of pluggable (provider-based) key managers and trust managers. A key manager is encapsulated by the javax.net.ssl.KeyManager class, and manages the keys used to perform authentication. A trust manager is encapsulated by the TrustManager class (in the same package), and makes decisions about who to trust based on certificates in the key store it manages.<p>The Java platform includes a built-in provider that implements the SSL/TLS protocols:<ul><li>SSLv3</li><li>TLSv1</li><li>TLSv1.1</li><li>TLSv1.2</li></ul>",
        "image": ""
      },
      {
        "text": "<b>SSL/TLS Handshake Sequence:</b><ul><li>Client requests a document from a secure server.</li><li>The server sends its X.509 certificate to the client with its public key.</li><li>The client checks whether the certificate has been issued by a CA it trusts.</li><li>The client compares the information in the certificate with the site's public key and domain name.</li><li>The client tells the server what cipher suites it has.</li><li>The server picks up the strongest mutually available cipher suite and notifies the client.</li><li>The client generates a session key (symmetric) and encrypts it using the server's public key and sends it to the server.</li><li>The server receives the encrypted session key and decrypts it using its private key.</li><li>The client and server use the session key to encrypt and decrypt the data they send to each other.</li></ul>",
        "image": ""
      },
      {
        "text": "<b>SASL:</b><p>Simple Authentication and Security Layer (SASL) is an Internet standard that specifies a protocol for authentication and optional establishment of a security layer between client and server applications. SASL defines how authentication data is to be exchanged, but does not itself specify the contents of that data. It is a framework into which specific authentication mechanisms that specify the contents and semantics of the authentication data can fit. There are a number of standard SASL mechanisms defined by the Internet community for various security levels and deployment scenarios.<p>The Java SASL API defines classes and interfaces for applications that use SASL mechanisms. It is defined to be mechanism-neutral; an application that uses the API need not be hardwired into using any particular SASL mechanism. Applications can select the mechanism to use based on desired security features. The API supports both client and server applications. The javax.security.sasl.Sasl class is used to create SaslClient and SaslServer objects.<p>SASL mechanism implementations are supplied in provider packages. Each provider may support one or more SASL mechanisms and is registered and invoked via the standard provider architecture.<p>The Java platform includes a built-in provider that implements the following SASL mechanisms: <ul><li>CRAM-MD5, DIGEST-MD5, EXTERNAL, GSSAPI, NTLM, and PLAIN client mechanisms</li><li>CRAM-MD5, DIGEST-MD5, GSSAPI, and NTLM server mechanisms</li></ul>",
        "image": ""
      },
      {
        "text": "<b>GSS-API and Kerberos:</b><p>The Java platform contains an API with the Java language bindings for the Generic Security Service Application Programming Interface (GSS-API). GSS-API offers application programmers uniform access to security services atop a variety of underlying security mechanisms. The Java GSS-API currently requires use of a Kerberos v5 mechanism, and the Java platform includes a built-in implementation of this mechanism. At this time, it is not possible to plug in additional mechanisms. Note: The Krb5LoginModule mentioned in Section 6 can be used in conjunction with the GSS Kerberos mechanism.<p>The Java platform also includes a built-in implementation of the Simple and Protected GSSAPI Negotiation Mechanism (SPNEGO) GSS-API mechanism.<p>Before two applications can use the Java GSS-API to securely exchange messages between them, they must establish a joint security context. The context encapsulates shared state information that might include, for example, cryptographic keys. Both applications create and use an org.ietf.jgss.GSSContext object to establish and maintain the shared information that makes up the security context. Once a security context has been established, it can be used to prepare secure messages for exchange.<p>The Java GSS APIs are in the org.ietf.jgss package. The Java platform also defines basic Kerberos classes, like KerberosPrincipal, KerberosTicket, KerberosKey, and KeyTab, which are located in the javax.security.auth.kerberos package.",
        "image": ""
      }
    ]
  },
  {
    "id": 50,
    "date": "2015/10/31",
    "title": "SSO and SAML",
    "itemList": [
      {
        "text": "Single sign-on (SSO) is a user session authentication process that permits a user to enter one user credential in order to access multiple applications. The process authenticates the user for all the applications they have been given rights to and eliminates further prompts when they switch applications during a particular session.<p>As different applications and resources support different authentication mechanisms, single sign-on must internally translate and store credentials for the different mechanisms, from the credential used for initial authentication.<p>Other shared authentication schemes not to be confused with SSO include OAuth, OpenID, OpenID Connect and Facebook Connect, which require the user to enter their login credentials each time they access a different site or application.",
        "image": ""
      },
      {
        "text": "<b>Common configurations</b><br/><ul><li><b>Security Assertion Markup Language:</b> Security Assertion Markup Language (SAML) is an XML-based solution for exchanging user security information between an enterprise and a service provider. It supports W3C XML encryption and service provider initiated web browser single sign-on exchanges. A user wielding a user agent (usually a web browser) is called the subject in the SAML-based single sign-on. The user requests a web resource protected by a SAML service provider. The service provider, wishing to know the identity of the requesting user, issues an authentication request to a SAML identity provider through the user agent. The identity provider is the one that provides the user credentials. The service provider trusts the identity provider of the user information, to provide access to its services or resources.</li><li><b>Kerberos based:</b></li><li><b>Smart card based:</b></li><li><b>Integrated Windows Authentication:</b></li></ul>",
        "image": ""
      },
      {
        "text": "<b>SAML 2.0 Assertions</b><br/>An assertion is a package of information that supplies zero or more statements made by a SAML authority. SAML assertions are usually made about a subject, represented by the &lt;Subject&gt; element. The SAML 2.0 specification defines three different kinds of assertion statements that can be created by a SAML authority. All SAML-defined statements are associated with a subject. The three kinds of statements defined are as follows:<p><ul><li><b>Authentication Assertion:</b> The assertion subject was authenticated by a particular means at a particular time.</li><li><b>Attribute Assertion:</b> The assertion subject is associated with the supplied attributes.</li><li><b>Authorization Decision Assertion:</b> A request to allow the assertion subject to access the specified resource has been granted or denied.</li></ul>",
        "image": ""
      },
      {
        "text": "<b>How SAML works</b><br/>The SAML specification defines three roles: the principal (typically a user), the identity provider (IdP), and the service provider (SP). In the use case addressed by SAML, the principal requests a service from the service provider. The service provider requests and obtains an identity assertion from the identity provider. On the basis of this assertion, the service provider can make an access control decision – in other words it can decide whether to perform some service for the connected principal.<br/>Before delivering the identity assertion to the SP, the IdP may request some information from the principal – such as a user name and password – in order to authenticate the principal. SAML specifies the assertions between the three parties: in particular, the messages that assert identity that are passed from the IdP to the SP. In SAML, one identity provider may provide SAML assertions to many service providers. Similarly, one SP may rely on and trust assertions from many independent IdPs.<br/>SAML does not specify the method of authentication at the identity provider; it may use a username and password, or other form of authentication, including multi-factor authentication. A directory service such as LDAP, RADIUS, or Active Directory that allows users to log in with a user name and password is a typical source of authentication tokens at an identity provider. The popular Internet social networking services also provide identity services that in theory could be used to support SAML exchanges.",
        "image": ""
      }
    ]
  },
  {
    "id": 55,
    "date": "2015/10/31",
    "title": "Json Web Token (JWT)",
    "itemList": [
      {
        "text": "JSON Web Token (JWT) is an open standard that defines a compact and self-contained way for securely transmitting information between parties as a JSON object. This information can be verified and trusted because it is digitally signed. JWTs can be signed using a secret (with the HMAC algorithm) or a public/private key pair using RSA or ECDSA.",
        "image": ""
      },
      {
        "text": "<b>Here are some scenarios where JSON Web Tokens are useful:</b><ul><li><b>Authorization:</b> This is the most common scenario for using JWT. Once the user is logged in, each subsequent request will include the JWT, allowing the user to access routes, services, and resources that are permitted with that token. Single Sign On is a feature that widely uses JWT nowadays, because of its small overhead and its ability to be easily used across different domains.</li><li><b>Information Exchange:</b> JSON Web Tokens are a good way of securely transmitting information between parties. Because JWTs can be signed—for example, using public/private key pairs—you can be sure the senders are who they say they are. Additionally, as the signature is calculated using the header and the payload, you can also verify that the content hasn't been tampered with.</li></ul>",
        "image": ""
      },
      {
        "text": "<b>JSON Web Token structure</b><br/><p>In its compact form, JSON Web Tokens consist of three parts separated by dots (.), and takes the form of <mark>xxxxx.yyyyy.zzzzz</mark>. The three parts are: <ul><li><b>Header: </b>The header typically consists of two parts: <ul><li><b>typ: </b>the type of the token, which is JWT</li><li><b>alg: </b>the signing algorithm being used, such as HMAC SHA256 or RSA</li></ul></li><li><b>Payload: </b>this contains the claims. Claims are statements about an entity (typically, the user) and additional data. There are three types of claims:<ul><li><b>Registered claims: </b>These are a set of predefined claims which are not mandatory but recommended, to provide a set of useful, interoperable claims. Some of them are: <ul><li>iss (issuer)</li><li>exp (expiration time)</li><li>sub (subject)</li><li>aud (audience)</li><li>and others</li></ul></li><li><b>Public claims: </b>These can be defined at will by those using JWTs. But to avoid collisions they should be defined in the IANA JSON Web Token Registry or be defined as a URI that contains a collision resistant namespace.</li><li><b>Private claims: </b>These are the custom claims created to share information between parties that agree on using them and are neither registered or public claims.</li></ul></li><li><b>Signature: </b>the signature is create by using the algorithm specified in the header, and hash the encoded header, the encoded payload, a secret, and sign that. The signature is used to verify the message wasn't changed along the way, and, in the case of tokens signed with a private key, it can also verify that the sender of the JWT is who it says it is.</li></ul>",
        "image": ""
      },
      {
        "text": "<b>How do JSON Web Tokens work?</b><br/><p>In authentication, when the user successfully logs in using their credentials, a JSON Web Token will be returned. Since tokens are credentials, great care must be taken to prevent security issues. In general, you should not keep tokens longer than required.</p><p>Whenever the user wants to access a protected route or resource, the user agent should send the JWT, typically in the Authorization header using the Bearer schema. </p>",
        "image": ""
      },
      {
        "text": "<b>Verify the JWT</b><br/><p>To validate a JWT, your application needs to:<ol><li>Check that the JWT is well formed</li><li>Check the signature</li><li>Check the standard claims</li></ol></p>",
        "image": ""
      }
    ]
  },
  {
    "id": 60,
    "date": "2015/11/3",
    "title": "OAuth, OpenID and OATH",
    "itemList": [
      {
        "text": "<b>OAuth</b><p>OAuth is an open standard for authorization. OAuth provides client applications a 'secure delegated access' to server resources on behalf of a resource owner. It specifies a process for resource owners to authorize third-party access to their server resources without sharing their credentials. Designed specifically to work with HTTP, OAuth essentially allows access tokens to be issued to third-party clients by an authorization server, with the approval of the resource owner, or end-user. The client then uses the access token to access the protected resources hosted by the resource server. OAuth is commonly used as a way for web surfers to log into third party web sites using their Microsoft, Google, Facebook or Twitter accounts, without worrying about their access credentials being compromised.<p>OAuth is a service that is complementary to, and therefore distinct from, OpenID. OAuth is also distinct from OATH, which is a reference architecture for authentication, not a standard for authorization.<br/><br/>The following picture shows a typical Oauth success response token:",
        "image": "../assets/image/it/security/oauthToken.PNG"
      },
      {
        "text": "<b>OpenID</b><p>OpenID (OID) is an open standard and decentralized protocol by the non-profit OpenID Foundation that allows users to be authenticated by certain co-operating sites (known as Relying Parties or RP) using a third party service. This eliminates the need for webmasters to provide their own ad hoc systems and allowing users to consolidate their digital identities. In other words, users can log into multiple unrelated websites without having to register with their information over and over again; Several large organizations either issue or accept OpenIDs on their websites according to the OpenID Foundation: AOL, Blogger, Flickr, France Telecom, Google, Hyves, LiveJournal, Microsoft (provider name Microsoft account), Mixi, Myspace, Novell, Orange, Sears, Sun, Telecom Italia, Universal Music Group, VeriSign, WordPress, and Yahoo!. Other providers are BBC, IBM, PayPal, Steam, along with GitHub, Identi.ca, Last.fm, Linkedin, and Twitter. However, some of those organizations also develop their own authentication management such as Novell Modular Authentication Service (NMAS), and Facebook stopped using OpenID and instead uses Facebook Connect.",
        "image": ""
      },
      {
        "text": "<b>OpenID Connect</b><p>OpenID Connect is a “profile” of OAuth 2.0 specifically designed for attribute release and authentication.</p><p>From a technical perspective, the big difference between OpenID Connect and OAuth 2.0 is the id_token–there is no id_token defined in OAuth 2.0 because it is specific to federated authentication.</p><p>The id_token provides an additional layer of security to user sign in transactions by adding:<ul><li>A nonce, which is sent by the client and enables the integrity of the response to be validated</li><li>A hash of the access token</li><li>A hash of the code (optional)</li></ul></p>",
        "image": ""
      },
      {
        "text": "<b>OpenID Connect vs SAML</b><p>At the risk of over-simplification, OpenID Connect is a rewrite of SAML using OAuth 2.0. Let’s look at a few similarities and differences…</p>",
        "image": ""
      },
      {
        "text": "<b>IDP / SP vs. OP / RP</b><p>In SAML, the user is redirected from the Service Provider (SP) to the Identity Provider (IDP) for sign in.</p><p>In OpenID Connect, the user is redirected from the Relying Party (RP) to the OpenID Provider (OP) for sign in.</p><p>The SAML SP is always a website. The OpenID Connect RP is either a web or mobile application, and is frequently called the “client” because it extends an OAuth 2.0 client.</p>",
        "image": ""
      },
      {
        "text": "<b>Assertion vs. id_token</b><p>In SAML, there is an “assertion”–a signed XML document with the subject information (who authenticated), attributes (info about the person), the issuer (who issued the assertion), and other information about the authentication event.</p><p>The equivalent in OpenID Connect is the id_token. This is a signed JSON document that contains the subject, issuer, and authentication information.</p>",
        "image": ""
      },
      {
        "text": "<b>OATH</b><p>Initiative for Open Authentication (OATH) is an industry-wide collaboration to develop an open reference architecture using open standards to promote the adoption of strong authentication. It has close to thirty coordinating and contributing members and is proposing standards for a variety of authentication technologies, with the aim of lowering costs and simplifying their use.</p><p>An OATH token is a secure one time password that can be used for two factor authentication.  The first factor is something you know (a password, mother's maiden name, the whereabouts of Jimmy Hoffa) while the second factor is something you have (a smartphone, email address, etc.).  The OATH token is sent to something you have as a one time password to increase security in authentication.</p><p>OATH is not related to OAuth, an open standard for authorization.</p>",
        "image": ""
      }
    ]
  },
  {
    "id": 70,
    "date": "2017/10/12",
    "title": "SSL/TLS Algorithms",
    "itemList": [
      {
        "text": "<b>Symmetric Algorithms:</b><p><ul><li><mark>DES:</mark> The Data Encryption Standard was adopted as a U.S. government standard in 1977 and as an ANSI standard in 1981. The DES is a block cipher that uses a 56-bit key and has several different operating modes depending on the purpose for which it is employed. The DES is a strong algorithm, but today the short key length limits its use. Indeed, in 1998 a special-purpose machine for 'cracking DES' was created by the Electronic Frontier Foundation (EFF) for under $250,000. In one demonstration, it found the key to an encrypted message in less than a day in conjunction with a coalition of computer users around the world.</li><li><mark>3DES:</mark> Triple-DES is a way to make the DES dramatically more secure by using the DES encryption algorithm three times with three different keys, for a total key length of 168 bits. Also called '3DES' this algorithm has been widely used by financial institutions and by the Secure Shell program (ssh). Simply using the DES twice with two different keys does not improve its security to the extent that one might at first suspect because of a theoretical plaintext attack called meet-in-the-middle, in which an attacker simultaneously attempts encrypting the plaintext with a single DES operation and decrypting the ciphertext with another single DES operation until a match is made in the middle. Triple-DES avoids this vulnerability.</li><li><mark>Blowfish</mark> Blowfish is a fast, compact, and simple block encryption algorithm invented by Bruce Schneier. The algorithm allows a variable-length key, up to 448 bits, and is optimized for execution on 32- or 64-bit processors. The algorithm is unpatented and has been placed in the public domain. Blowfish is used in the Secure Shell and other programs.</li><li><mark>ARCFOUR:</mark></li><li><mark>AES:</mark> This block cipher was developed by Joan Daemen and Vincent Rijmen, and was chosen in October 2000 by the National Institute of Standards and Technology to be the U.S.'s new Advanced Encryption Standard. Rijndael is an extraordinarily fast and compact cipher that can use keys that are 128, 192, or 256 bits long.</li><li><mark>Camellia:</mark></li><li><mark>RC2:</mark></li><li><mark>IDEA:</mark></li><li><mark>SEED:</mark></li></ul>",
        "image": ""
      },
      {
        "text": "<b>Asymmetric Algorithms:</b><p><ul><li><mark>Diffie-Hellman:</mark> Diffie-Hellman key agreement algorithm was developed by Dr. Whitfield Diffie and Dr. Martin Hellman in 1976. Diffie-Hellman algorithm is not for encryption or decryption but it enable two parties who are involved in communication to generate a shared secret key for exchanging information confidentially.</li><li><mark>RSA:</mark> Rivest Shamir Adleman (RSA): Ron Rivest, Adi Shamir, and Len Adleman released the Rivest-Shamir-Adleman (RSA) public key algorithm in 1978. This algorithm can be used for encrypting and signing data. The encryption and signing processes are performed through a series of modular multiplications.</li><li><mark>ECC: </mark>Elliptic-curve cryptography (ECC) is an approach to public-key cryptography based on the algebraic structure of elliptic curves over finite fields. ECC requires smaller keys compared to non-EC cryptography (based on plain Galois fields) to provide equivalent security.</li><li><mark>ElGamal:</mark></li><li><mark>DSA:</mark> The Digital Signature Algorithm (DSA) was developed by the United States government for digital signatures. Digital Signature Algorithm can be used only for signing data and it cannot be used for encryption. The DSA signing process is performed through a series of calculations based on a selected prime number. Although intended to have a maximum key size of 1,024 bits, longer key sizes are now supported.</li></ul>",
        "image": ""
      },
      {
        "text": "<b>Common Hash Functions for Message Digest:</b><p>A hash function is any function that can be used to map data of arbitrary size to data of a fixed size. The values returned by a hash function are called hash values, hash codes, digests, or simply hashes.<ul><li><mark>MD5:</mark> The MD5 message-digest algorithm is a widely used hash function producing a 128-bit hash value. Although MD5 was initially designed to be used as a cryptographic hash function, it has been found to suffer from extensive vulnerabilities. It can still be used as a checksum to verify data integrity, but only against unintentional corruption. It remains suitable for other non-cryptographic purposes, for example for determining the partition for a particular key in a partitioned database.<br/><br/> One basic requirement of any cryptographic hash function is that it should be computationally infeasible to find two distinct messages which hash to the same value. MD5 fails this requirement catastrophically; such collisions can be found in seconds on an ordinary home computer.</li><li><mark>SHA:</mark> SHA-2 (Secure Hash Algorithm 2) is a set of cryptographic hash functions designed by the United States National Security Agency (NSA).[3] They are built using the Merkle–Damgård structure, from a one-way compression function itself built using the Davies–Meyer structure from a (classified) specialized block cipher. <br/><br/>SHA-2 includes significant changes from its predecessor, SHA-1. The SHA-2 family consists of six hash functions with digests (hash values) that are 224, 256, 384 or 512 bits: SHA-224, SHA-256, SHA-384, SHA-512, SHA-512/224, SHA-512/256.</li></ul>",
        "image": ""
      }
    ]
  },
  {
    "id": 80,
    "date": "2019/02/06",
    "title": "Cipher Suite",
    "itemList": [
      {
        "text": "<p>A cipher suite is a set of algorithms that help secure a network connection that uses Transport Layer Security (TLS) or its now-deprecated predecessor Secure Socket Layer (SSL). The set of algorithms that cipher suites usually contain include: a key exchange algorithm, a bulk encryption algorithm, and a message authentication code (MAC) algorithm.</p><p>The key exchange algorithm is used to exchange a key between two devices. This key is used to encrypt and decrypt the messages being sent between two machines. The bulk encryption algorithm is used to encrypt the data being sent. The MAC algorithm provides data integrity checks to ensure that the data sent does not change in transit. In addition, cipher suites can include signatures and an authentication algorithm to help authenticate the server and or client.</p>",
        "image": ""
      },
      {
        "text": "<b>Stream vs Block Ciphers</b><p>There are two major types of ciphers: block and stream. Block ciphers process entire blocks at a time, usually many bytes in length. If there is not enough data to make a complete input block, the data must be padded: that is, before encryption, dummy bytes must be added to make a multiple of the cipher's block size. These bytes are then stripped off during the decryption phase. The padding can either be done by the application, or by initializing a cipher to use a padding type such as 'PKCS5PADDING'. In contrast, stream ciphers process incoming data one small unit (typically a byte or even a bit) at a time. This allows for ciphers to process an arbitrary amount of data without padding.",
        "image": ""
      }
    ]
  },
  {
    "id": 90,
    "date": "2019/02/07",
    "title": "keytool",
    "itemList": [
      {
        "text": "<p>keytool is a Key and Certificate Management Tool. It Manages a keystore (database) of cryptographic keys, X.509 certificate chains, and trusted certificates.</p>",
        "image": ""
      },
      {
        "text": "<b>COMMAND AND OPTION NOTES</b><p><ul><li>keytool -help</li><li>keytool -printcert {-file cert_file} {-v}, Note: The -v option can appear for all commands except -help. If it appears, it signifies 'verbose' mode; more information will be output.</li><li>keytool -genkeypair</li><li>keytool -exportcert -alias mykey -file MJ.cer</li><li>keytool -importcert -alias abc -file ABCCA.cer</li><li>keytool -certreq -file MarkJ.csr</li><li>keytool -importkeystore</li></ul>",
        "image": ""
      }
    ]
  },
  {
    "id": 90,
    "date": "2019/01/29",
    "title": "OWASP Top 10 Application Security Risks",
    "itemList": [
      {
        "text": "<b>Injection:</b><p>Injection flaws, such as SQL, NoSQL, OS, and LDAP injection, occur when untrusted data is sent to an interpreter as part of a command or query. The attacker’s hostile data can trick the interpreter into executing unintended commands or accessing data without proper authorization.</p>",
        "image": ""
      },
      {
        "text": "<b>Broken Authentication:</b><p>Application functions related to authentication and session management are often implemented incorrectly, allowing attackers to compromise passwords, keys, or session tokens, or to exploit other implementation flaws to assume other users’ identities temporarily or permanently.</p>",
        "image": ""
      },
      {
        "text": "<b>Sensitive Data Exposure:</b><p>Many web applications and APIs do not properly protect sensitive data, such as financial, healthcare, and PII. Attackers may steal or modify such weakly protected data to conduct credit card fraud, identity theft, or other crimes. Sensitive data may be compromised without extra protection, such as encryption at rest or in transit, and requires special precautions when exchanged with the browser.</p>",
        "image": ""
      },
      {
        "text": "<b>XML External Entities (XXE):</b><p>Many older or poorly configured XML processors evaluate external entity references within XML documents. External entities can be used to disclose internal files using the file URI handler, internal file shares, internal port scanning, remote code execution, and denial of service attacks.</p>",
        "image": ""
      },
      {
        "text": "<b>Broken Access Control:</b><p>Restrictions on what authenticated users are allowed to do are often not properly enforced. Attackers can exploit these flaws to access unauthorized functionality and/or data, such as access other users' accounts, view sensitive files, modify other users’ data, change access rights, etc.</p>",
        "image": ""
      },
      {
        "text": "<b>Security Misconfiguration:</b><p>Security misconfiguration is the most commonly seen issue. This is commonly a result of insecure default configurations, incomplete or ad hoc configurations, open cloud storage, misconfigured HTTP headers, and verbose error messages containing sensitive information. Not only must all operating systems, frameworks, libraries, and applications be securely configured, but they must be patched and upgraded in a timely fashion.</p>",
        "image": ""
      },
      {
        "text": "<b>Cross-Site Scripting (XSS):</b><p>XSS flaws occur whenever an application includes untrusted data in a new web page without proper validation or escaping, or updates an existing web page with user-supplied data using a browser API that can create HTML or JavaScript. XSS allows attackers to execute scripts in the victim’s browser which can hijack user sessions, deface web sites, or redirect the user to malicious sites.</p>",
        "image": ""
      },
      {
        "text": "<b>Insecure Deserialization:</b><p>Insecure deserialization often leads to remote code execution. Even if deserialization flaws do not result in remote code execution, they can be used to perform attacks, including replay attacks, injection attacks, and privilege escalation attacks.</p>",
        "image": ""
      },
      {
        "text": "<b>Using Components with Known Vulnerabilities:</b><p>Components, such as libraries, frameworks, and other software modules, run with the same privileges as the application. If a vulnerable component is exploited, such an attack can facilitate serious data loss or server takeover. Applications and APIs using components with known vulnerabilities may undermine application defenses and enable various attacks and impacts.</p>",
        "image": ""
      },
      {
        "text": "<b>Insufficient Logging & Monitoring:</b><p>Insufficient logging and monitoring, coupled with missing or ineffective integration with incident response, allows attackers to further attack systems, maintain persistence, pivot to more systems, and tamper, extract, or destroy data. Most breach studies show time to detect a breach is over 200 days, typically detected by external parties rather than internal processes or monitoring.</p>",
        "image": ""
      }
    ]
  }
]